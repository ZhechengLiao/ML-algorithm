{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP28FKFiT79GaRJRJZP66HA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZhechengLiao/ML-algorithm/blob/master/LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Logistic from Scratch"
      ],
      "metadata": {
        "id": "17E4PgMZqktP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "p7cEvDehoGIF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "x_train = iris.data[:-50, :2]  # we only take the first two features.\n",
        "y_train = iris.target[:-50]"
      ],
      "metadata": {
        "id": "BKNRxTqLoPOE"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(w, x):\n",
        "  z = w.dot(x.T)\n",
        "  return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "def loss(y, y_pred):\n",
        "  return -np.mean(y*np.log(y_pred) + (1-y)*np.log(1-y_pred))\n",
        "\n",
        "def gradient(x, y, y_pred):\n",
        "  return 1/x.shape[0] * np.dot(x.T, (y_pred-y))\n",
        "\n",
        "def hessian(x):\n",
        "  return 1/x.shape[0] * np.sum(np.dot(sigmoid(w, x)*(1-sigmoid(w, x)), x.dot(x.T)))\n",
        "\n",
        "def newton(x, y, y_pred):\n",
        "  # f'(x) / f''(x) => grad / H\n",
        "  return gradient(x, y, y_pred) / hessian(x)"
      ],
      "metadata": {
        "id": "xYZTt1hToXD2"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.zeros(2)\n",
        "lr = 0.1\n",
        "epoch_num = 10\n",
        "loss(y_train, sigmoid(w, x_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07B4_WueZfem",
        "outputId": "94a18bab-2271-4b82-a8aa-ae567efac49d"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6931471805599453"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epoch_num):\n",
        "  grad = gradient(x_train, y_train, sigmoid(w, x_train))\n",
        "  w -= lr*grad\n",
        "  l = loss(y_train, sigmoid(w, x_train))\n",
        "  print(f'epoch: {epoch + 1}, loss: {l}, weight: {w}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAu-O1fJqkDl",
        "outputId": "4a174940-3a3a-4798-9ac1-dc89f6bce602"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss: 0.6248255301804133, weight: [ 0.14528919 -0.23305451]\n",
            "epoch: 2, loss: 0.6193129814982582, weight: [ 0.15683884 -0.25355026]\n",
            "epoch: 3, loss: 0.6138882652113291, weight: [ 0.16829707 -0.27388142]\n",
            "epoch: 4, loss: 0.608549815425159, weight: [ 0.17966478 -0.29404964]\n",
            "epoch: 5, loss: 0.6032960859969277, weight: [ 0.19094285 -0.31405656]\n",
            "epoch: 6, loss: 0.5981255509739806, weight: [ 0.20213218 -0.3339038 ]\n",
            "epoch: 7, loss: 0.5930367049802403, weight: [ 0.21323366 -0.35359301]\n",
            "epoch: 8, loss: 0.5880280635527795, weight: [ 0.22424817 -0.37312582]\n",
            "epoch: 9, loss: 0.5830981634308278, weight: [ 0.23517662 -0.39250388]\n",
            "epoch: 10, loss: 0.5782455627994861, weight: [ 0.24601989 -0.4117288 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Newton Method"
      ],
      "metadata": {
        "id": "rSi_pgLTtUDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epoch_num):\n",
        "  w -= newton(x_train, y_train, sigmoid(w, x_train))\n",
        "  l = loss(y_train, sigmoid(w, x_train))\n",
        "  print(f'epoch:{epoch}, loss: {l}, weight: {w}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcdot2uAtP5J",
        "outputId": "12d1e59d-5026-4617-a4c7-018328c9dcef"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:0, loss: 0.5781960357602896, weight: [ 0.24613101 -0.4119258 ]\n",
            "epoch:1, loss: 0.578146515870384, weight: [ 0.24624212 -0.41212278]\n",
            "epoch:2, loss: 0.5780970031283117, weight: [ 0.24635323 -0.41231975]\n",
            "epoch:3, loss: 0.578047497532615, weight: [ 0.24646433 -0.41251671]\n",
            "epoch:4, loss: 0.577997999081837, weight: [ 0.24657542 -0.41271365]\n",
            "epoch:5, loss: 0.577948507774521, weight: [ 0.24668651 -0.41291058]\n",
            "epoch:6, loss: 0.577899023609211, weight: [ 0.24679759 -0.4131075 ]\n",
            "epoch:7, loss: 0.5778495465844504, weight: [ 0.24690866 -0.41330441]\n",
            "epoch:8, loss: 0.5778000766987845, weight: [ 0.24701973 -0.4135013 ]\n",
            "epoch:9, loss: 0.5777506139507574, weight: [ 0.24713078 -0.41369819]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch logistic regression"
      ],
      "metadata": {
        "id": "6mT4nORKnKvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "iris = datasets.load_iris()\n",
        "x_train = torch.tensor(iris.data[:-50, :2], dtype=torch.float32)  # we only take the first two features.\n",
        "y_train = torch.tensor(iris.target[:-50], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "4qVyBSiao0Lt"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "  def __init__(self, inputDim, outputDim):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = torch.nn.Linear(inputDim, outputDim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = torch.sigmoid(self.linear(x))\n",
        "    return output"
      ],
      "metadata": {
        "id": "-SbAcEQZOTuM"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(2, 1)\n",
        "lr = 0.1\n",
        "loss = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "epoch_num = 10"
      ],
      "metadata": {
        "id": "GndhHX1fnKNF"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epoch_num):\n",
        "  optimizer.zero_grad()\n",
        "  output = model(x_train)\n",
        "  l = loss(torch.squeeze(output), y_train)\n",
        "  l.backward()\n",
        "  optimizer.step()\n",
        "  print(f'epoch:{epoch+1}, loss:{l}, weigts:{[(w, b) for w, b in model.named_parameters()]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkujT9ATn_Re",
        "outputId": "505d2081-468e-401c-9abd-2cc323b9f4fa"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1, loss:1.835126519203186, weigts:[('linear.weight', Parameter containing:\n",
            "tensor([[ 0.4575, -0.0856]], requires_grad=True)), ('linear.bias', Parameter containing:\n",
            "tensor([-0.1800], requires_grad=True))]\n",
            "epoch:2, loss:1.0330897569656372, weigts:[('linear.weight', Parameter containing:\n",
            "tensor([[ 0.2692, -0.2204]], requires_grad=True)), ('linear.bias', Parameter containing:\n",
            "tensor([-0.2183], requires_grad=True))]\n",
            "epoch:3, loss:0.6400909423828125, weigts:[('linear.weight', Parameter containing:\n",
            "tensor([[ 0.2144, -0.2779]], requires_grad=True)), ('linear.bias', Parameter containing:\n",
            "tensor([-0.2321], requires_grad=True))]\n",
            "epoch:4, loss:0.6038058400154114, weigts:[('linear.weight', Parameter containing:\n",
            "tensor([[ 0.2243, -0.2986]], requires_grad=True)), ('linear.bias', Parameter containing:\n",
            "tensor([-0.2341], requires_grad=True))]\n",
            "epoch:5, loss:0.5985633134841919, weigts:[('linear.weight', Parameter containing:\n",
            "tensor([[ 0.2357, -0.3182]], requires_grad=True)), ('linear.bias', Parameter containing:\n",
            "tensor([-0.2357], requires_grad=True))]\n",
            "epoch:6, loss:0.5934197902679443, weigts:[('linear.weight', Parameter containing:\n",
            "tensor([[ 0.2470, -0.3376]], requires_grad=True)), ('linear.bias', Parameter containing:\n",
            "tensor([-0.2374], requires_grad=True))]\n",
            "epoch:7, loss:0.5883576273918152, weigts:[('linear.weight', Parameter containing:\n",
            "tensor([[ 0.2581, -0.3569]], requires_grad=True)), ('linear.bias', Parameter containing:\n",
            "tensor([-0.2391], requires_grad=True))]\n",
            "epoch:8, loss:0.5833753347396851, weigts:[('linear.weight', Parameter containing:\n",
            "tensor([[ 0.2692, -0.3761]], requires_grad=True)), ('linear.bias', Parameter containing:\n",
            "tensor([-0.2407], requires_grad=True))]\n",
            "epoch:9, loss:0.5784714221954346, weigts:[('linear.weight', Parameter containing:\n",
            "tensor([[ 0.2803, -0.3951]], requires_grad=True)), ('linear.bias', Parameter containing:\n",
            "tensor([-0.2423], requires_grad=True))]\n",
            "epoch:10, loss:0.5736444592475891, weigts:[('linear.weight', Parameter containing:\n",
            "tensor([[ 0.2912, -0.4139]], requires_grad=True)), ('linear.bias', Parameter containing:\n",
            "tensor([-0.2440], requires_grad=True))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for weight, bias in model.named_parameters():\n",
        "  print(weight, bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QiMGBV7t3JA",
        "outputId": "544abbad-5f69-4906-ee08-eabc5aace4a0"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear.weight Parameter containing:\n",
            "tensor([[-0.3982,  0.1895]], requires_grad=True)\n",
            "linear.bias Parameter containing:\n",
            "tensor([-0.2033], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mrmgzzJ4umXv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}